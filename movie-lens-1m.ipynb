{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a1cb2e7-286d-4132-9482-0f2e30905b51",
   "metadata": {},
   "source": [
    "# 0. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf3e63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:11.386668Z",
     "iopub.status.busy": "2026-01-08T04:54:11.386444Z",
     "iopub.status.idle": "2026-01-08T04:54:19.519612Z",
     "shell.execute_reply": "2026-01-08T04:54:19.518855Z",
     "shell.execute_reply.started": "2026-01-08T04:54:11.386621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from scipy.sparse import csr_matrix\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6326f6e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:19.521609Z",
     "iopub.status.busy": "2026-01-08T04:54:19.521199Z",
     "iopub.status.idle": "2026-01-08T04:54:19.525400Z",
     "shell.execute_reply": "2026-01-08T04:54:19.524678Z",
     "shell.execute_reply.started": "2026-01-08T04:54:19.521585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ML_PATH = \"ml-1m\"\n",
    "USERS_PATH = ML_PATH + \"/users.dat\"\n",
    "MOVIES_PATH = ML_PATH + \"/movies.dat\"\n",
    "RATINGS_PATH = ML_PATH + \"/ratings.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d9cc6-358c-4a07-9458-27eb538727f9",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15232a28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:19.526778Z",
     "iopub.status.busy": "2026-01-08T04:54:19.526431Z",
     "iopub.status.idle": "2026-01-08T04:54:19.618917Z",
     "shell.execute_reply": "2026-01-08T04:54:19.618065Z",
     "shell.execute_reply.started": "2026-01-08T04:54:19.526733Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>gender</th>\n",
       "      <th>ageCode</th>\n",
       "      <th>occupationCode</th>\n",
       "      <th>zipCode</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Under 18</td>\n",
       "      <td>K-12 student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "      <td>56+</td>\n",
       "      <td>self-employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "      <td>25-34</td>\n",
       "      <td>scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "      <td>45-49</td>\n",
       "      <td>executive/managerial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "      <td>25-34</td>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId gender  ageCode  occupationCode zipCode       age  \\\n",
       "0       1      F        1              10   48067  Under 18   \n",
       "1       2      M       56              16   70072       56+   \n",
       "2       3      M       25              15   55117     25-34   \n",
       "3       4      M       45               7   02460     45-49   \n",
       "4       5      M       25              20   55455     25-34   \n",
       "\n",
       "             occupation  \n",
       "0          K-12 student  \n",
       "1         self-employed  \n",
       "2             scientist  \n",
       "3  executive/managerial  \n",
       "4                writer  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df = pd.read_csv(USERS_PATH, sep=\"::\", names=['userId', 'gender', 'ageCode', 'occupationCode', 'zipCode'])\n",
    "age_code_mapping = {1:  \"Under 18\", 18:  \"18-24\", 25:  \"25-34\", 35:  \"35-44\", 45:  \"45-49\", 50:  \"50-55\", 56:  \"56+\"}\n",
    "users_df['age'] = users_df['ageCode'].map(age_code_mapping)\n",
    "occupation_code_mapping = {\n",
    "    0:  \"other\",\n",
    "\t1:  \"academic/educator\",\n",
    "\t2:  \"artist\",\n",
    "\t3:  \"clerical/admin\",\n",
    "\t4:  \"college/grad student\",\n",
    "\t5:  \"customer service\",\n",
    "\t6:  \"doctor/health care\",\n",
    "\t7:  \"executive/managerial\",\n",
    "\t8:  \"farmer\",\n",
    "\t9:  \"homemaker\",\n",
    "\t10:  \"K-12 student\",\n",
    "\t11:  \"lawyer\",\n",
    "\t12:  \"programmer\",\n",
    "\t13:  \"retired\",\n",
    "\t14:  \"sales/marketing\",\n",
    "\t15:  \"scientist\",\n",
    "\t16:  \"self-employed\",\n",
    "\t17:  \"technician/engineer\",\n",
    "\t18:  \"tradesman/craftsman\",\n",
    "\t19:  \"unemployed\",\n",
    "\t20:  \"writer\"\n",
    "}\n",
    "users_df['occupation'] = users_df['occupationCode'].map(occupation_code_mapping)\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b159e3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:19.620796Z",
     "iopub.status.busy": "2026-01-08T04:54:19.619860Z",
     "iopub.status.idle": "2026-01-08T04:54:19.669384Z",
     "shell.execute_reply": "2026-01-08T04:54:19.668892Z",
     "shell.execute_reply.started": "2026-01-08T04:54:19.620762Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title                        genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Children's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Children's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId             title      genres\n",
       "0        1  Toy Story (1995)   Animation\n",
       "0        1  Toy Story (1995)  Children's\n",
       "0        1  Toy Story (1995)      Comedy\n",
       "1        2    Jumanji (1995)   Adventure\n",
       "1        2    Jumanji (1995)  Children's"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movies_df = pd.read_csv(MOVIES_PATH, sep=\"::\", names=['movieId', 'title', 'genres'], encoding='latin-1')\n",
    "movies_genre_df = movies_df.copy()\n",
    "movies_genre_df['genres'] = movies_genre_df['genres'].map(lambda x: x.split(\"|\"))\n",
    "movies_genre_df = movies_genre_df.explode('genres')\n",
    "display(movies_df.head())\n",
    "display(movies_genre_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b43c0bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:19.670394Z",
     "iopub.status.busy": "2026-01-08T04:54:19.670136Z",
     "iopub.status.idle": "2026-01-08T04:54:24.004578Z",
     "shell.execute_reply": "2026-01-08T04:54:24.003939Z",
     "shell.execute_reply.started": "2026-01-08T04:54:19.670370Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = pd.read_csv(RATINGS_PATH, sep=\"::\", names=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5edf246-fff8-4fe2-aacd-d47fd0d8be2d",
   "metadata": {},
   "source": [
    "# 2. Evaluation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a60f10-2f86-42dd-a8dd-e80e03b670f2",
   "metadata": {},
   "source": [
    "## 2.A. Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3762792-fd6c-4fcc-93f2-d735cb6783b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:24.005681Z",
     "iopub.status.busy": "2026-01-08T04:54:24.005432Z",
     "iopub.status.idle": "2026-01-08T04:54:24.012477Z",
     "shell.execute_reply": "2026-01-08T04:54:24.011924Z",
     "shell.execute_reply.started": "2026-01-08T04:54:24.005654Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def random_split(df, user_id_col, movie_id_col, holdout_fraction=0.2):\n",
    "    test = df.sample(frac=holdout_fraction, replace=False, random_state=42)\n",
    "    train = df[~df.index.isin(test.index)]\n",
    "    users_train = train[user_id_col].unique()\n",
    "    movies_train = train[movie_id_col].unique()\n",
    "    train_users_count = len(users_train)\n",
    "    train_movies_count = len(movies_train)\n",
    "    test_users_count = len(test[user_id_col].unique())\n",
    "    test_movies_count = len(test[movie_id_col].unique())\n",
    "    print(f\"Train count: {len(train)}\")\n",
    "    print(f\"Train users count: {train_users_count}\")\n",
    "    print(f\"Train movies count: {train_movies_count}\")\n",
    "    print(f\"Test count: {len(test)}\")\n",
    "    print(f\"Test users count: {test_users_count}\")\n",
    "    print(f\"Test movies count: {test_movies_count}\")\n",
    "\n",
    "    users_train = train[user_id_col].unique()\n",
    "    movies_train = train[movie_id_col].unique()\n",
    "    test = test[(test[user_id_col].isin(users_train)) & (test[movie_id_col].isin(movies_train))]\n",
    "    print(\"Truncating test users & items invalid for CF completed.\")\n",
    "    print(f\"Test count: {len(test)}\")\n",
    "    test_users_count_after = len(test[user_id_col].unique())\n",
    "    test_movies_count_after = len(test[movie_id_col].unique())\n",
    "    print(f\"Test users count: {test_users_count_after}\")\n",
    "    print(f\"{(1- (test_users_count_after/test_users_count))*100:.4f}% of users truncated.\")\n",
    "    print(f\"Test movies count: {test_movies_count_after}\")\n",
    "    print(f\"{(1- (test_movies_count_after/test_movies_count))*100:.4f}% of movies truncated.\")\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac337a1-4dbe-403a-9fd2-96393032be71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:24.014889Z",
     "iopub.status.busy": "2026-01-08T04:54:24.014617Z",
     "iopub.status.idle": "2026-01-08T04:54:24.141884Z",
     "shell.execute_reply": "2026-01-08T04:54:24.141185Z",
     "shell.execute_reply.started": "2026-01-08T04:54:24.014870Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 900188\n",
      "Train users count: 6040\n",
      "Train movies count: 3694\n",
      "Test count: 100021\n",
      "Test users count: 5970\n",
      "Test movies count: 3294\n",
      "Truncating test users & items invalid for CF completed.\n",
      "Test count: 100009\n",
      "Test users count: 5970\n",
      "0.0000% of users truncated.\n",
      "Test movies count: 3282\n",
      "0.3643% of movies truncated.\n"
     ]
    }
   ],
   "source": [
    "rnd_train_df, rnd_test_df = random_split(ratings_df, user_id_col='userId', movie_id_col='movieId', holdout_fraction=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5464df55-d017-4e08-881e-c398bfdca4d5",
   "metadata": {},
   "source": [
    "## 2.B. Leave-One-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8705f2e4-2cf3-4f41-9749-b2562a91bfda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:24.142986Z",
     "iopub.status.busy": "2026-01-08T04:54:24.142754Z",
     "iopub.status.idle": "2026-01-08T04:54:24.148988Z",
     "shell.execute_reply": "2026-01-08T04:54:24.148330Z",
     "shell.execute_reply.started": "2026-01-08T04:54:24.142965Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def leave_one_out_split(df, user_id_col, movie_id_col, holdout_fraction=0.2):\n",
    "    df['rank'] = df.sort_values(['timestamp'], ascending=True) \\\n",
    "             .groupby(['userId']) \\\n",
    "             .cumcount() + 1\n",
    "    test = df[df['rank'] == 1]\n",
    "    train = df[df['rank'] > 1]\n",
    "    movies_train = train[movie_id_col].unique()\n",
    "    train_users_count = len(train[user_id_col].unique())\n",
    "    train_movies_count = len(movies_train)\n",
    "    test_users_count = len(test[user_id_col].unique())\n",
    "    test_movies_count = len(test[movie_id_col].unique())\n",
    "    print(f\"Train count: {len(train)}\")\n",
    "    print(f\"Train users count: {train_users_count}\")\n",
    "    print(f\"Train movies count: {train_movies_count}\")\n",
    "    print(f\"Test count: {len(test)}\")\n",
    "    print(f\"Test users count: {test_users_count}\")\n",
    "    print(f\"Test movies count: {test_movies_count}\")\n",
    "    \n",
    "    test = test[(test[movie_id_col].isin(movies_train))]\n",
    "    print(\"Truncating test items invalid for CF completed.\")\n",
    "    test_movies_count_after = len(test[movie_id_col].unique())\n",
    "    print(f\"Test movies count: {test_movies_count_after}\")\n",
    "    print(f\"{(1- (test_movies_count_after/test_movies_count))*100:.4f}% of movies truncated.\")\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee0d9566-121d-43c2-ab52-09a955b38708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:24.150358Z",
     "iopub.status.busy": "2026-01-08T04:54:24.149820Z",
     "iopub.status.idle": "2026-01-08T04:54:24.382378Z",
     "shell.execute_reply": "2026-01-08T04:54:24.381661Z",
     "shell.execute_reply.started": "2026-01-08T04:54:24.150336Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 994169\n",
      "Train users count: 6040\n",
      "Train movies count: 3702\n",
      "Test count: 6040\n",
      "Test users count: 6040\n",
      "Test movies count: 1684\n",
      "Truncating test items invalid for CF completed.\n",
      "Test movies count: 1680\n",
      "0.2375% of movies truncated.\n"
     ]
    }
   ],
   "source": [
    "loo_train_df, loo_test_df = leave_one_out_split(ratings_df, user_id_col='userId', movie_id_col='movieId', holdout_fraction=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf64ed9-a61a-4ff9-8df3-8a1ba85dc221",
   "metadata": {},
   "source": [
    "## 2.C. Global Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e03c181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:24.383726Z",
     "iopub.status.busy": "2026-01-08T04:54:24.383414Z",
     "iopub.status.idle": "2026-01-08T04:54:24.390545Z",
     "shell.execute_reply": "2026-01-08T04:54:24.389940Z",
     "shell.execute_reply.started": "2026-01-08T04:54:24.383697Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def global_temporal_split(df, timestamp_col, user_id_col, movie_id_col, holdout_fraction=0.2):\n",
    "    cutoff_date = df[timestamp_col].quantile(q=1-holdout_fraction)\n",
    "    test = df[df[timestamp_col] > cutoff_date]\n",
    "    train = df[df[timestamp_col] <= cutoff_date]\n",
    "    users_train = train[user_id_col].unique()\n",
    "    movies_train = train[movie_id_col].unique()\n",
    "    train_users_count = len(users_train)\n",
    "    train_movies_count = len(movies_train)\n",
    "    test_users_count = len(test[user_id_col].unique())\n",
    "    test_movies_count = len(test[movie_id_col].unique())\n",
    "    print(\"Split completed.\")\n",
    "    print(f\"Train count: {len(train)}\")\n",
    "    print(f\"Train users count: {train_users_count}\")\n",
    "    print(f\"Train movies count: {train_movies_count}\")\n",
    "    print(f\"Test count: {len(test)}\")\n",
    "    print(f\"Test users count: {test_users_count}\")\n",
    "    print(f\"Test movies count: {test_movies_count}\")\n",
    "    \n",
    "    # make sure all users in test are in train\n",
    "    users_train = train[user_id_col].unique()\n",
    "    movies_train = train[movie_id_col].unique()\n",
    "    test = test[(test[user_id_col].isin(users_train)) & (test[movie_id_col].isin(movies_train))]\n",
    "    print(\"Truncating test users & items invalid for CF completed.\")\n",
    "    print(f\"Test count: {len(test)}\")\n",
    "    test_users_count_after = len(test[user_id_col].unique())\n",
    "    test_movies_count_after = len(test[movie_id_col].unique())\n",
    "    print(f\"Test users count: {test_users_count_after}\")\n",
    "    print(f\"{(1- (test_users_count_after/test_users_count))*100:.4f}% of users truncated.\")\n",
    "    print(f\"Test movies count: {test_movies_count_after}\")\n",
    "    print(f\"{(1- (test_movies_count_after/test_movies_count))*100:.4f}% of movies truncated.\")\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00c2f7af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:24.391708Z",
     "iopub.status.busy": "2026-01-08T04:54:24.391430Z",
     "iopub.status.idle": "2026-01-08T04:54:24.490103Z",
     "shell.execute_reply": "2026-01-08T04:54:24.489479Z",
     "shell.execute_reply.started": "2026-01-08T04:54:24.391680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split completed.\n",
      "Train count: 900188\n",
      "Train users count: 6011\n",
      "Train movies count: 3678\n",
      "Test count: 100021\n",
      "Test users count: 1209\n",
      "Test movies count: 3407\n",
      "Truncating test users & items invalid for CF completed.\n",
      "Test count: 95723\n",
      "Test users count: 1179\n",
      "2.4814% of users truncated.\n",
      "Test movies count: 3377\n",
      "0.8805% of movies truncated.\n"
     ]
    }
   ],
   "source": [
    "gts_train_df, gts_test_df = global_temporal_split(ratings_df, timestamp_col='timestamp', user_id_col = 'userId', movie_id_col='movieId', holdout_fraction=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cc88d6-65c3-4bff-a0ae-b8f4fb2aa10e",
   "metadata": {},
   "source": [
    "# Prep Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a76b90ce-ac12-430e-93b6-708086de5229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:24.491223Z",
     "iopub.status.busy": "2026-01-08T04:54:24.490985Z",
     "iopub.status.idle": "2026-01-08T04:54:24.496146Z",
     "shell.execute_reply": "2026-01-08T04:54:24.495520Z",
     "shell.execute_reply.started": "2026-01-08T04:54:24.491201Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_valid_idx(train_df, test_df):\n",
    "    user_idx_mapping = {original_id: i for i, original_id in enumerate(train_df['userId'].unique())}\n",
    "    movie_idx_mapping = {original_id: i for i, original_id in enumerate(train_df['movieId'].unique())}\n",
    "    train_df['userId_idx'] = train_df['userId'].map(user_idx_mapping)\n",
    "    test_df['userId_idx'] = test_df['userId'].map(user_idx_mapping)\n",
    "    train_df['movieId_idx'] = train_df['movieId'].map(movie_idx_mapping)\n",
    "    test_df['movieId_idx'] = test_df['movieId'].map(movie_idx_mapping)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5b1fa60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:24.497371Z",
     "iopub.status.busy": "2026-01-08T04:54:24.497063Z",
     "iopub.status.idle": "2026-01-08T04:54:24.659462Z",
     "shell.execute_reply": "2026-01-08T04:54:24.658937Z",
     "shell.execute_reply.started": "2026-01-08T04:54:24.497341Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gts_train_df, gts_test_df = create_valid_idx(gts_train_df, gts_test_df)\n",
    "loo_train_df, loo_test_df = create_valid_idx(loo_train_df, loo_test_df)\n",
    "rnd_train_df, rnd_test_df = create_valid_idx(rnd_train_df, rnd_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9481dd84-4ba4-4123-974c-6ed3c96156dc",
   "metadata": {},
   "source": [
    "# 3. Defining Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069a694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PRDataset(Dataset):\n",
    "    def __init__(self, user_ids, item_ids, user_liked_train, all_itemIds):\n",
    "        self.user_ids = torch.IntTensor(user_ids)\n",
    "        self.item_ids = torch.IntTensor(item_ids)\n",
    "        self.user_liked_train = user_liked_train\n",
    "        self.all_itemIds = all_itemIds\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        curr_userId = self.user_ids[index]\n",
    "        curr_pos_itemId = self.item_ids[index]\n",
    "        user_liked_items = self.user_liked_train[curr_userId]\n",
    "        user_neg_items = list(set(self.all_item_ids) - set(user_liked_items))\n",
    "        user_neg_item = np.random.choice(user_neg_items)\n",
    "        \n",
    "        return (curr_userId, curr_pos_itemId, torch.IntTensor(user_neg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparation:\n",
    "    def __init__(self, train_df, test_df, user_col_ori, item_col_ori, rating_col, implicit, threshold):\n",
    "        self.train_df = train_df.copy()\n",
    "        self.test_df = test_df.copy()\n",
    "        self.user_col_ori = user_col_ori\n",
    "        self.item_col_ori = item_col_ori\n",
    "        self.rating_col = rating_col\n",
    "        self.implicit = implicit\n",
    "        self.threshold = threshold\n",
    "        if implicit:\n",
    "            self._convert_df_to_implicit()\n",
    "        \n",
    "        self.n_users = train_df[user_col_ori].nunique()\n",
    "        self.n_items = train_df[item_col_ori].nunique()\n",
    "        self.train_user_ids = list(train_df[user_col_ori].unique())\n",
    "        self.train_item_ids = list(train_df[item_col_ori].unique())\n",
    "        self.test_user_ids = list(test_df[user_col_ori].unique())\n",
    "        self.test_item_ids = list(test_df[item_col_ori].unique())\n",
    "        \n",
    "        self.set_userId_sequenced_map()\n",
    "        self.set_itemId_sequenced_map()\n",
    "        \n",
    "        self.item_user_matrix = self._build_item_user_train_occurence_matrix()\n",
    "        self.user_seen_map = self._build_user_seen_map()\n",
    "        self.user_ground_truth = self._build_user_ground_truth()\n",
    "        self.user_liked_train = self._build_user_liked_train()\n",
    "    \n",
    "    def _convert_df_to_implicit(self):\n",
    "        \"\"\"Convert dataframe from 5-star rating to implicit signals\n",
    "        \"\"\"\n",
    "        if self.implicit:\n",
    "            self.train_df[self.rating_col] = self.train_df[self.rating_col].map(lambda x: 1 if x >= self.threshold else 0)\n",
    "            self.test_df[self.rating_col] = self.test_df[self.rating_col].map(lambda x: 1 if x >= self.threshold else 0)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    def set_userId_sequenced_map(self):\n",
    "        \"\"\"set a dictionary of {original userId: transformed userId}\n",
    "        \"\"\"\n",
    "        self.userId_map = {original_id: i for i, original_id in enumerate(self.train_user_ids)}\n",
    "    \n",
    "    def set_itemId_sequenced_map(self):\n",
    "        \"\"\"set a dictionary of {original itemId: transformed itemId}\n",
    "        \"\"\"\n",
    "        self.itemId_map = {original_id: i for i, original_id in enumerate(self.train_item_ids)}\n",
    "        \n",
    "    def _build_item_user_train_occurence_matrix(self):\n",
    "        \"\"\"get sparse matrix of item-user interaction in train set with n_rows = n_items and n_cols = n_users\n",
    "        Return: csr_matrix\n",
    "        \"\"\"\n",
    "        item_user_matrix = csr_matrix(\n",
    "            (np.ones(len(self.train_df)), \n",
    "             ([self.itemId_map[i] for i in self.train_df[self.item_col_ori].values], \n",
    "              [self.userId_map[u] for u in self.train_df[self.user_col_ori].values])\n",
    "            ), \n",
    "            shape=(self.n_items, self.n_users)\n",
    "        )\n",
    "        \n",
    "        return item_user_matrix\n",
    "    \n",
    "    def _build_user_seen_map(self):\n",
    "        \"\"\"Get a dictionary map of {user: set of itemIds the user interacted with in train set}\n",
    "        Return: dict\n",
    "        \"\"\"\n",
    "        user_seen_map = self.train_df.groupby(self.user_col_ori)[self.item_col_ori].apply(set).to_dict()\n",
    "        \n",
    "        return user_seen_map\n",
    "    \n",
    "    def _build_user_ground_truth(self):\n",
    "        \"\"\"Get a dictionary map of {user: itemIds that are liked by user in test set}\n",
    "        Return: dict\n",
    "        \"\"\"\n",
    "        \n",
    "        # Filter out disliked items\n",
    "        if self.implicit:\n",
    "            liked_df = self.test_df[self.test_df[self.rating_col] == 1.0]\n",
    "        else:\n",
    "            liked_df = self.test_df[self.test_df[self.rating_col] >= self.threshold]\n",
    "        \n",
    "        user_ground_truth = liked_df.groupby(self.user_col_ori)[self.item_col_ori].apply(set).to_dict()\n",
    "        \n",
    "        return user_ground_truth\n",
    "    \n",
    "    def _build_user_liked_train(self):\n",
    "        \"\"\"Get a dictionary map of {user: itemIds that are liked by user in train set}\n",
    "        Return: dict\n",
    "        \"\"\"\n",
    "        \n",
    "        # Filter out disliked items\n",
    "        if self.implicit:\n",
    "            liked_df = self.train_df[self.train_df[self.rating_col] == 1.0]\n",
    "        else:\n",
    "            liked_df = self.train_df[self.train_df[self.rating_col] >= self.threshold]\n",
    "        \n",
    "        user_liked_train = liked_df.groupby(self.user_col_ori)[self.item_col_ori].apply(set).to_dict()\n",
    "        \n",
    "        return user_liked_train\n",
    "    \n",
    "    def create_dataloader(self, set_type, batch_size: int, shuffle: bool) -> DataLoader:\n",
    "        \"\"\"Helper to create PyTorch DataLoader.\"\"\"\n",
    "        if set_type == \"train\":\n",
    "            df = self.train_df\n",
    "        else:\n",
    "            df = self.test_df\n",
    "        \n",
    "        user_ids = torch.IntTensor([self.userId_map[u] for u in df[self.user_col_ori].values])\n",
    "        item_ids = torch.IntTensor([self.itemId_map[i] for i in df[self.item_col_ori].values])\n",
    "        ratings = torch.FloatTensor(df[self.rating_col].values)\n",
    "        \n",
    "        dataset = TensorDataset(user_ids, item_ids, ratings)\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "    def create_pr_dataloader(self, set_type, batch_size: int, shuffle: bool) -> DataLoader:\n",
    "        if set_type == \"train\":\n",
    "            df = self.train_df\n",
    "        else:\n",
    "            df = self.test_df\n",
    "            \n",
    "        if self.implicit:\n",
    "            liked_df = df[df[self.rating_col] == 1.0]\n",
    "        else:\n",
    "            liked_df = df[df[self.rating_col] >= self.threshold]\n",
    "        \n",
    "        user_ids = [self.userId_map[u] for u in liked_df[self.user_col_ori].values]\n",
    "        liked_item_ids = [self.itemId_map[i] for i in liked_df[self.item_col_ori].values]\n",
    "        \n",
    "        all_item_ids = set(self.train_item_ids)\n",
    "        user_liked_train = self.user_liked_train()\n",
    "        \n",
    "        dataset = PRDataset(user_ids, liked_item_ids, user_liked_train, all_item_ids)\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a2f78-4506-4e7e-875f-a934db5148ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:25.032163Z",
     "iopub.status.busy": "2026-01-08T04:54:25.031952Z",
     "iopub.status.idle": "2026-01-08T04:54:25.036119Z",
     "shell.execute_reply": "2026-01-08T04:54:25.035566Z",
     "shell.execute_reply.started": "2026-01-08T04:54:25.032143Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BaseRecommender(ABC):\n",
    "    @abstractmethod\n",
    "    def fit(self, train_df, test_df=None):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def recommend_all(self, k):\n",
    "        pass\n",
    "    @abstractmethod\n",
    "    def recommend_for_user(self, userId, k):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905e6962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:25.072512Z",
     "iopub.status.busy": "2026-01-08T04:54:25.071912Z",
     "iopub.status.idle": "2026-01-08T04:54:25.090256Z",
     "shell.execute_reply": "2026-01-08T04:54:25.089750Z",
     "shell.execute_reply.started": "2026-01-08T04:54:25.072489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prhn_at_k(ranked_list: list, user_actuals: list, k=10):\n",
    "    user_actuals_set = set(user_actuals)\n",
    "    if not user_actuals_set:\n",
    "        return 0.0, 0.0, 0.0, 0.0\n",
    "    top_k_items = ranked_list[:k]\n",
    "    true_positives = [(rank, item) for rank, item in enumerate(top_k_items) \n",
    "                      if item in user_actuals_set]\n",
    "    \n",
    "    precision = len(true_positives) / k\n",
    "    recall = len(true_positives) / len(user_actuals_set)\n",
    "    hit = 1.0 if len(true_positives) > 0 else 0.0\n",
    "    dcg = sum(1.0 / np.log2(rank + 2) for rank, item in true_positives)\n",
    "    num_possible = min(k, len(user_actuals_set))\n",
    "    idcg = sum(1.0 / np.log2(i + 2) for i in range(num_possible))\n",
    "    ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    "    \n",
    "    return precision, recall, hit, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a7cc17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T05:16:40.441476Z",
     "iopub.status.busy": "2026-01-08T05:16:40.440872Z",
     "iopub.status.idle": "2026-01-08T05:16:40.447207Z",
     "shell.execute_reply": "2026-01-08T05:16:40.446599Z",
     "shell.execute_reply.started": "2026-01-08T05:16:40.441447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prhn_evaluator(model, all_liked_items, user_seen_map, train_df, test_df, k=10, implicit=False):\n",
    "    all_userIds = set(test_df['userId_idx'])\n",
    "    all_itemIds = set(train_df['movieId_idx'])\n",
    "    \n",
    "    precisions, recalls, hits, ndcgs = 0, 0, 0, 0\n",
    "    \n",
    "    all_recommendations = model.recommend_all(all_userIds, all_itemIds, user_seen_map, k)\n",
    "    for u in all_userIds:\n",
    "        user_predictions = all_recommendations[u]\n",
    "        user_actuals = all_liked_items[u]\n",
    "        p, r, h, n = prhn_at_k(user_predictions, user_actuals, k)\n",
    "        precisions += p\n",
    "        recalls += r\n",
    "        hits += h\n",
    "        ndcgs += n\n",
    "        \n",
    "    num_users = len(all_userIds)\n",
    "    return precisions/num_users, recalls/num_users, hits/num_users, ndcgs/num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, dataprep):\n",
    "        self.dataprep = dataprep\n",
    "        self.user_seen_map = dataprep.user_seen_map\n",
    "        self.user_ground_truth = dataprep.user_ground_truth\n",
    "        \n",
    "    def _prepare_evaluation(self, ranked_list: list, user_actuals: list, k:int):\n",
    "        user_actuals_set = set(user_actuals)\n",
    "        if not user_actuals_set:\n",
    "            return 0.0, 0.0, 0.0, 0.0\n",
    "        top_k_items = ranked_list[:k]\n",
    "        true_positives = [(rank, item) for rank, item in enumerate(top_k_items) \n",
    "                        if item in user_actuals_set]\n",
    "        return true_positives, user_actuals_set\n",
    "    \n",
    "    def _precision_at_k(self, true_positives, user_actuals_set=None, k=None):\n",
    "        return len(true_positives)/k\n",
    "    \n",
    "    def _recall_at_k(self, true_positives, user_actuals_set, k=None):\n",
    "        return len(true_positives) / len(user_actuals_set)\n",
    "    \n",
    "    def _hit_at_k(self, true_positives, user_actuals_set=None, k=None):\n",
    "        return 1.0 if len(true_positives) > 0 else 0.0\n",
    "    \n",
    "    def _ndcg_at_k(self, true_positives, user_actuals_set, k):\n",
    "        dcg = sum(1.0 / np.log2(rank + 2) for rank, item in true_positives)\n",
    "        num_possible = min(k, len(user_actuals_set))\n",
    "        idcg = sum(1.0 / np.log2(i + 2) for i in range(num_possible))\n",
    "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    "        \n",
    "        return ndcg\n",
    "        \n",
    "    def evaluate(self, recommender, metrics=None, k=10):\n",
    "        if metrics is None:\n",
    "            metrics = ['precision', 'recall', 'hit', 'ndcg']\n",
    "        \n",
    "        if self.user_ground_truth is None:\n",
    "            raise ValueError(\"Must call set_user_ground_truth() before evaluate()\")\n",
    "        \n",
    "        test_userIds = set(self.dataprep.test_df[self.dataprep.user_col_seq])\n",
    "        train_itemIds = set(self.dataprep.train_df[self.dataprep.movie_col_seq])\n",
    "        \n",
    "        all_recommendations = recommender.recommend_all(test_userIds, train_itemIds, self.user_seen_map, k)\n",
    "        \n",
    "        metric_functions = {\n",
    "            'precision': self._precision_at_k,\n",
    "            'recall': self._recall_at_k,\n",
    "            'hit': self._hit_at_k,\n",
    "            'ndcg': self._ndcg_at_k\n",
    "        }\n",
    "        \n",
    "        results = {f'{metric}@{k}': [] for metric in metrics}\n",
    "        \n",
    "        for u in test_userIds:\n",
    "            if u not in self.user_ground_truth:\n",
    "                continue\n",
    "            \n",
    "            user_predictions = all_recommendations[u]\n",
    "            user_actuals = self.user_ground_truth[u]\n",
    "            \n",
    "            true_positives, user_actuals_set = self._prepare_evaluation(user_predictions, user_actuals, k)\n",
    "            \n",
    "            for metric in metrics:\n",
    "                if metric in metric_functions:\n",
    "                    score = metric_functions[metric](true_positives, user_actuals_set, k)\n",
    "                    results[f'{metric}@{k}'].append(score)\n",
    "            \n",
    "        return {name: np.mean(scores) for name, scores in results.items()}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "921ea701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:25.109036Z",
     "iopub.status.busy": "2026-01-08T04:54:25.108798Z",
     "iopub.status.idle": "2026-01-08T04:54:25.122000Z",
     "shell.execute_reply": "2026-01-08T04:54:25.121448Z",
     "shell.execute_reply.started": "2026-01-08T04:54:25.109011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BPRLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Bayesian Personalized Ranking Loss.\n",
    "    Optimizes: user should prefer positive item over negative item.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, pos_scores, neg_scores):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pos_scores: Predictions for positive items\n",
    "            neg_scores: Predictions for negative items\n",
    "        \n",
    "        Returns:\n",
    "            BPR loss value\n",
    "        \"\"\"\n",
    "        return -torch.mean(torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c4913a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T05:12:21.380052Z",
     "iopub.status.busy": "2026-01-08T05:12:21.379424Z",
     "iopub.status.idle": "2026-01-08T05:12:21.400176Z",
     "shell.execute_reply": "2026-01-08T05:12:21.399390Z",
     "shell.execute_reply.started": "2026-01-08T05:12:21.380021Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PyTorchTrainer:\n",
    "    def __init__(self, training_configs, device, evaluator):\n",
    "        self.training_configs = training_configs\n",
    "        self.device = device\n",
    "        self.evaluator = evaluator\n",
    "        self.history = None\n",
    "    \n",
    "    def train(self, model, train_loader, test_loader, recommender=None):\n",
    "        batch_size = self.training_configs['batch_size']\n",
    "        num_epochs = self.training_configs['num_epochs']\n",
    "        criterion = self.training_configs['criterion']\n",
    "        optimizer = self.training_configs['optimizer']\n",
    "        \n",
    "        train_loss_list = []\n",
    "        if isinstance(criterion, BPRLoss):\n",
    "            test_ndcg_list = []\n",
    "            self.history = {'train_loss': [], 'test_ndcg': []}\n",
    "        else:\n",
    "            test_loss_list = []\n",
    "            self.history = {'train_loss': [], 'test_loss': []}\n",
    "            \n",
    "        model.to(self.device)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            \n",
    "            for batch in train_loader:\n",
    "                if isinstance(criterion, BPRLoss):\n",
    "                    user_ids, pos_item_ids, neg_item_ids = batch\n",
    "                    user_ids = user_ids.to(self.device)\n",
    "                    pos_item_ids = pos_item_ids.to(self.device)\n",
    "                    neg_item_ids = neg_item_ids.to(self.device)\n",
    "                    \n",
    "                    pos_pred = self.model(user_ids, pos_item_ids)\n",
    "                    neg_pred = self.model(user_ids, neg_item_ids)\n",
    "                    \n",
    "                    loss = self.criterion(pos_pred, neg_pred)\n",
    "                else:\n",
    "                    user_ids, item_ids, ratings = batch\n",
    "                    user_ids = user_ids.to(self.device)\n",
    "                    item_ids = item_ids.to(self.device)\n",
    "                    ratings = ratings.to(self.device).float()\n",
    "                    \n",
    "                    predictions = model(user_ids, item_ids)\n",
    "                    loss = criterion(predictions, ratings)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            train_loss = total_loss / len(train_loader)\n",
    "            \n",
    "            if isinstance(criterion, BPRLoss):\n",
    "                train_loss_list.append(train_loss)\n",
    "            else:\n",
    "                train_loss_list.append(np.sqrt(train_loss))\n",
    "        \n",
    "            if isinstance(criterion, BPRLoss):\n",
    "                if recommender is None:\n",
    "                    raise ValueError(\"recommender must be passed for implicit training\")\n",
    "                test_ndcg = self.evaluator.evaluate(recommender, ['ndcg'], k=10)\n",
    "\n",
    "                test_ndcg_list.append(test_ndcg)\n",
    "            else:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for batch in test_loader:\n",
    "                        user_id, item_id, rating = batch\n",
    "                        user_id = user_id.to(self.device)\n",
    "                        item_id = item_id.to(self.device)\n",
    "                        rating = rating.to(self.device).float()\n",
    "                        \n",
    "                        prediction = model(user_id, item_id)\n",
    "                        loss = criterion(prediction, rating)\n",
    "                        test_total_loss += loss.item()\n",
    "                \n",
    "                test_loss = test_total_loss / len(test_loader)\n",
    "                test_loss_list.append(np.sqrt(test_loss))\n",
    "                \n",
    "            if isinstance(criterion, BPRLoss):\n",
    "                print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, '\n",
    "                      f'Test NDCG: {test_ndcg:.4f}')\n",
    "            else:\n",
    "                print(f'Epoch {epoch+1}, Train Loss: {np.sqrt(train_loss):.4f}, '\n",
    "                      f'Test Loss: {np.sqrt(test_loss):.4f}')\n",
    "        \n",
    "        if isinstance(criterion, BPRLoss):\n",
    "            self.history = {'train_loss': train_loss_list, 'test_ndcg': test_ndcg_list}\n",
    "        else:\n",
    "            self.history = {'train_loss': train_loss_list, 'test_loss': test_loss_list}\n",
    "            \n",
    "        self._plot_train_test()\n",
    "        \n",
    "        return model, self.history\n",
    "    \n",
    "    def _plot_train_test_loss(self):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "    \n",
    "        plt.subplot(1, 2, 1)\n",
    "        for key, value in self.history:\n",
    "            plt.plot(self.history[key], label=key)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Plot')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6c28886-2d2b-4a61-a192-912d51379d24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:25.123275Z",
     "iopub.status.busy": "2026-01-08T04:54:25.123018Z",
     "iopub.status.idle": "2026-01-08T04:54:25.140014Z",
     "shell.execute_reply": "2026-01-08T04:54:25.139508Z",
     "shell.execute_reply.started": "2026-01-08T04:54:25.123249Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "\n",
    "    def forward(self, user_id, item_id):\n",
    "        user_matrix = self.user_embedding(user_id)\n",
    "        item_matrix = self.item_embedding(item_id)\n",
    "        user_bias = self.user_bias(user_id)\n",
    "        item_bias = self.item_bias(item_id)\n",
    "        output = (user_matrix * item_matrix).sum(dim=1) + user_bias.squeeze() + item_bias.squeeze()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4fab42-8c1d-4783-b9e4-d23daf722666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T05:19:52.930789Z",
     "iopub.status.busy": "2026-01-08T05:19:52.930467Z",
     "iopub.status.idle": "2026-01-08T05:19:52.942956Z",
     "shell.execute_reply": "2026-01-08T05:19:52.942280Z",
     "shell.execute_reply.started": "2026-01-08T05:19:52.930761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MFRecommender(BaseRecommender):\n",
    "    def __init__(self, dataprep, model, trainer, evaluator,\n",
    "                 device: torch.device\n",
    "                 ):\n",
    "        self.dataprep = dataprep\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.trainer = trainer\n",
    "        self.evaluator = evaluator\n",
    "        self.history = None\n",
    "        \n",
    "    def fit(self):\n",
    "        if not self.dataprep.implicit:\n",
    "            train_loader = self.dataprep.create_dataloader(self, self.dataprep.train_df, self.trainer.training_configs['batch_size'], True)\n",
    "            test_loader = self.dataprep.create_dataloader(self, self.dataprep.test_df, self.trainer.training_configs['batch_size'], False)\n",
    "            self.model, self.history = self.trainer.train(self.model, train_loader, test_loader, recommender=None)\n",
    "        else:\n",
    "            train_loader = self.dataprep.create_pr_dataloader(self, self.trainer.training_configs['batch_size'], True)\n",
    "            test_loader = self.dataprep.create_dataloader(self, self.dataprep.test_df, self.trainer.training_configs['batch_size'], False)\n",
    "            self.model, self.history = self.trainer.train(self.model, train_loader, test_loader, recommender=self)\n",
    "            \n",
    "        return self.model, self.history\n",
    "    \n",
    "    def recommend_for_user(self, userId, k):\n",
    "        userId_idx = int(self.dataprep.train_df[self.dataprep.train_df[self.dataprep.user_col_ori]==userId][self.dataprep.user_col_seq][0])\n",
    "        unseen_item_ids = list(set(self.dataprep.all_item_ids) - set(self.dataprep.user_seen_map[userId_idx]))\n",
    "        userId_idx = torch.tensor([userId_idx], dtype=torch.long, device=self.device)\n",
    "        unseen_item_ids_tensor = torch.tensor(unseen_item_ids, dtype=torch.long, device=self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            user_embedding = self.model.user_embedding(userId_idx)\n",
    "            item_embedding = self.model.item_embedding(unseen_item_ids_tensor)\n",
    "            user_bias = self.model.user_bias(userId_idx).view(-1, 1)\n",
    "            item_bias = self.model.item_bias(unseen_item_ids_tensor).view(1, -1)\n",
    "            \n",
    "            user_item_vector = torch.matmul(user_embedding, item_embedding.t()) + user_bias + item_bias\n",
    "            scores = user_item_vector.squeeze(0)\n",
    "            scores = scores.detach().cpu().numpy()\n",
    "            \n",
    "        \n",
    "        top_k_indices = np.argsort(-scores)[:k]\n",
    "        top_k_ids = [unseen_item_ids[i] for i in top_k_indices]\n",
    "        final_recommendations = {}\n",
    "        final_recommendations[\"id\"] = top_k_ids\n",
    "        if self.dataprep.implicit:\n",
    "            return pd.DataFrame(final_recommendations)\n",
    "        else:\n",
    "            top_k_scores = scores[top_k_indices]\n",
    "            final_recommendations[\"score\"] = top_k_scores\n",
    "            return pd.DataFrame(final_recommendations)\n",
    "    \n",
    "    def recommend_all(self, k):\n",
    "        sorted_userIds = sorted(self.dataprep.test_df[self.dataprep.user_col_seq].unique())\n",
    "        sorted_itemIds = sorted(self.dataprep.all_item_ids)\n",
    "\n",
    "        user_tensor = torch.tensor(sorted_userIds, dtype=torch.long, device=self.device)\n",
    "        item_tensor = torch.tensor(sorted_itemIds, dtype=torch.long, device=self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            user_embedding = self.model.user_embedding(user_tensor)\n",
    "            item_embedding = self.model.item_embedding(item_tensor)\n",
    "            user_bias = self.model.user_bias(user_tensor).view(-1, 1)\n",
    "            item_bias = self.model.item_bias(item_tensor).view(1, -1)\n",
    "\n",
    "            scores = (user_embedding @ item_embedding.T + user_bias + item_bias).cpu().numpy()\n",
    "\n",
    "        itemId_to_col = {item_id: i for i, item_id in enumerate(sorted_itemIds)}\n",
    "\n",
    "        final_recommendations = {}\n",
    "        for idx, u in enumerate(sorted_userIds):\n",
    "            seen_cols = [itemId_to_col[i] for i in self.dataprep.user_seen_map[u] if i in itemId_to_col]\n",
    "            scores[idx][seen_cols] = -np.inf\n",
    "\n",
    "            top_k_cols = np.argsort(-scores[idx])[:k]\n",
    "            final_recommendations[u] = [sorted_itemIds[i] for i in top_k_cols]\n",
    "\n",
    "        return final_recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48078d7-3f62-4a7f-810f-21ed97ca6039",
   "metadata": {},
   "source": [
    "## 3.E. Item-KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b97a574-e90d-442e-a2de-fb620c17cd4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T04:54:25.157656Z",
     "iopub.status.busy": "2026-01-08T04:54:25.157382Z",
     "iopub.status.idle": "2026-01-08T04:54:25.176951Z",
     "shell.execute_reply": "2026-01-08T04:54:25.176443Z",
     "shell.execute_reply.started": "2026-01-08T04:54:25.157612Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ItemKNN(BaseRecommender):\n",
    "    def __init__(self, k_neighbors: int, regularization: int, dataprep, model, trainer, evaluator,):\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.regularization = regularization\n",
    "        self.dataprep = dataprep\n",
    "        self.model = None\n",
    "        \n",
    "    def fit(self):\n",
    "        item_user_matrix = self.dataprep.item_user_occurence_matrix\n",
    "\n",
    "        co_counts = item_user_matrix.dot(item_user_matrix.T)\n",
    "    \n",
    "        item_counts = co_counts.diagonal()\n",
    "        sqrt_counts = np.sqrt(item_counts)\n",
    "        \n",
    "        co_counts_coo = co_counts.tocoo()\n",
    "        rows = co_counts_coo.row\n",
    "        cols = co_counts_coo.col\n",
    "        data = co_counts_coo.data\n",
    "        denominators = (sqrt_counts[rows] * sqrt_counts[cols]) + self.regularization\n",
    "        similarities = data / denominators\n",
    "        \n",
    "        sim_matrix = csr_matrix((similarities, (rows, cols)), shape=(self.dataprep.n_items, self.dataprep.n_items))\n",
    "        self.model = sim_matrix\n",
    "        return self.model\n",
    "    \n",
    "    def recommend_for_user(self, userId, k):\n",
    "        userId = int(self.dataprep.train_df[self.dataprep.train_df[self.dataprep.user_col_ori]==userId][self.dataprep.user_col_seq][0])\n",
    "        seen_items = list(self.dataprep.user_seen_map[userId])\n",
    "\n",
    "        user_vector = csr_matrix(\n",
    "            (np.ones(len(seen_items)), ([0]*len(seen_items), seen_items)),\n",
    "            shape=(1, self.model.shape[0])\n",
    "        )\n",
    "\n",
    "        scores = user_vector.dot(self.model).toarray().ravel()\n",
    "        scores[seen_items] = -np.inf\n",
    "\n",
    "        top_k = np.argsort(-scores)[:k]\n",
    "        return pd.DataFrame({\"id\": top_k})\n",
    "\n",
    "    \n",
    "    def recommend_all(self, k):\n",
    "        n_users = self.dataprep.test_df[self.dataprep.user_col_seq].nunique()\n",
    "        n_items = self.dataprep.n_items\n",
    "\n",
    "        user_item = csr_matrix(\n",
    "            (np.ones(len(self.dataprep.train_df)),\n",
    "            (self.dataprep.train_df[self.dataprep.user_col_seq], elf.dataprep.train_df[self.dataprep.item_col_seq])),\n",
    "            shape=(n_users, n_items)\n",
    "        )\n",
    "\n",
    "        scores = user_item.dot(self.model)\n",
    "\n",
    "        final = {}\n",
    "        all_userIds = set(self.dataprep.test_df[self.dataprep.user_col_seq].unique())\n",
    "        for u in all_userIds:\n",
    "            seen = list(self.dataprep.user_seen_map[u])\n",
    "            scores[u, seen] = -np.inf\n",
    "\n",
    "            top_k = np.argsort(-scores[u].toarray().ravel())[:k]\n",
    "            final[u] = top_k\n",
    "\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim(Adam, )\n",
    "training_configs = Configuration(optimizer )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0bd125-3771-497f-b0da-c0cfcb2f0748",
   "metadata": {},
   "source": [
    "## 3.F. Item-POP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131db1a2-6495-4630-8c6d-c2c562199f62",
   "metadata": {},
   "source": [
    "# 5. Defining Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188ce0b8-2bee-4cfb-ad7c-fed7f52ce23a",
   "metadata": {},
   "source": [
    "# 6. Experimentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae885e-f0da-4f0f-b321-e0c5649ad2a0",
   "metadata": {},
   "source": [
    "## 6.A. How do different splitting strategies affect explicit MF's model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63ecdde-bc2b-4432-ba23-88e3ff3f6113",
   "metadata": {},
   "source": [
    "## 6.B. Does implicit MF with pairwise loss performs better than explicit MF?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b7e077-91bf-4c60-9b67-2613cac9d484",
   "metadata": {},
   "source": [
    "## 6.C. How does NCF perform compared to previous models and baselines?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d027b-d757-4916-88e4-f00c2cf15878",
   "metadata": {},
   "source": [
    "## 6.D. How does Sequence-Aware RecSys perform compared to previous models and baselines?"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1114664,
     "sourceId": 1872300,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9178145,
     "sourceId": 14372209,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
